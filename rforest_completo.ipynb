{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4f940a5-3c0f-4aae-89fb-679509583edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/25 16:01:51 WARN SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.\n",
      "25/11/25 16:01:51 WARN SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/25 16:01:51 WARN SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.\n",
      "25/11/25 16:01:51 WARN SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.\n",
      "25/11/25 16:01:51 WARN SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.\n",
      "25/11/25 16:01:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/11/25 16:01:54 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/11/25 16:01:57 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Spark iniciado.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "os.environ['SPARK_HOME'] = \"/home/hadoop/spark\"\n",
    "sys.path.insert(0, \"/home/hadoop/spark/python\")\n",
    "sys.path.insert(0, \"/home/hadoop/spark/python/lib/py4j-0.10.9.7-src.zip\") \n",
    "sys.path.insert(0, \"/home/hadoop/spark/python/lib/pyspark.zip\")\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Analisis_Completo_Modelo_Guardado\") \\\n",
    "    .master(\"yarn\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.cores\", \"2\") \\\n",
    "    .config(\"spark.yarn.executor.memoryOverhead\", \"1024m\") \\\n",
    "    .config(\"spark.network.timeout\", \"600s\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"‚úÖ Spark iniciado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b63fff-9942-486e-ac2f-72b74fa85ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_modelo = \"/modelos/rf_all_features_v1\"\n",
    "print(f\"üìÇ Cargando modelo desde: {ruta_modelo} ...\")\n",
    "\n",
    "try:\n",
    "    model_cargado = PipelineModel.load(ruta_modelo)\n",
    "    print(\"‚úÖ Modelo cargado exitosamente.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error cargando el modelo: {str(e)}\")\n",
    "    spark.stop()\n",
    "    sys.exit(1)\n",
    "\n",
    "print(\"\\nüîç Extrayendo conocimientos del modelo...\")\n",
    "\n",
    "assembler_stage = model_cargado.stages[1] \n",
    "rf_stage = model_cargado.stages[-1]\n",
    "\n",
    "# Extraer nombres y valores\n",
    "nombres_columnas = assembler_stage.getInputCols()\n",
    "importancias = rf_stage.featureImportances.toArray()\n",
    "\n",
    "# Crear DataFrame de Pandas para visualizar\n",
    "df_importancia = pd.DataFrame({\n",
    "    'Columna': nombres_columnas,\n",
    "    'Importancia': importancias\n",
    "}).sort_values(by='Importancia', ascending=False)\n",
    "\n",
    "# Mostrar Tabla Top 20\n",
    "print(\"\\nüèÜ TOP 20 VARIABLES M√ÅS IMPORTANTES (Lo que aprendi√≥ el modelo):\")\n",
    "print(df_importancia.head(20))\n",
    "\n",
    "# Graficar\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importancia', y='Columna', data=df_importancia.head(20), palette='viridis')\n",
    "plt.title('Importancia de Caracter√≠sticas - Modelo RF Recuperado')\n",
    "plt.xlabel('Importancia (Gini)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d5e036-171e-4542-a140-6f5f666bf185",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ruta_test = \"/trafico_train_mini\"\n",
    "print(f\"\\nüß™ Evaluando rendimiento con datos de prueba: {ruta_test}\")\n",
    "\n",
    "# Cargar datos de prueba\n",
    "df_test = spark.read.parquet(ruta_test)\n",
    "\n",
    "# Generar Predicciones\n",
    "# (El modelo ya tiene el StringIndexer dentro, as√≠ que acepta la columna 'Label' cruda)\n",
    "print(\"    Generando predicciones...\")\n",
    "predictions = model_cargado.transform(df_test)\n",
    "\n",
    "# Optimizaci√≥n de memoria (Seleccionar solo lo necesario para evaluar)\n",
    "results = predictions.select(\"label_index\", \"prediction\")\n",
    "results.cache()\n",
    "\n",
    "# Calcular M√©tricas\n",
    "acc_eval = MulticlassClassificationEvaluator(labelCol=\"label_index\", metricName=\"accuracy\")\n",
    "f1_eval = MulticlassClassificationEvaluator(labelCol=\"label_index\", metricName=\"f1\")\n",
    "prec_eval = MulticlassClassificationEvaluator(labelCol=\"label_index\", metricName=\"weightedPrecision\")\n",
    "rec_eval = MulticlassClassificationEvaluator(labelCol=\"label_index\", metricName=\"weightedRecall\")\n",
    "\n",
    "print(\"\\nüìä RESULTADOS FINALES DE EVALUACI√ìN:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"üéØ Accuracy:  {acc_eval.evaluate(results):.2%}\")\n",
    "print(f\"‚öñÔ∏è F1-Score:  {f1_eval.evaluate(results):.2%}\")\n",
    "print(f\"‚úÖ Precision: {prec_eval.evaluate(results):.2%}\")\n",
    "print(f\"üîç Recall:    {rec_eval.evaluate(results):.2%}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Limpieza final\n",
    "results.unpersist()\n",
    "print(\"\\nüèÅ Proceso finalizado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
